{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT-Hindi English.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshwinDeshpande96/Machine-Translation/blob/master/NMT_Hindi_English.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PKx85whf9Gi",
        "colab_type": "text"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKM8zjsx-RQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f712601-59f6-421d-9658-2117d60f9cb6"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# Import TensorFlow >= 1.10 and enable eager execution\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import inflect\n",
        "from google.colab import files\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2-IsX8TgCsA",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u41lkwsUgHrf",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Upload files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2KKuZWoVXyY",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "057d5dd4-9677-4def-a319-8dfe41e58236"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f3543a61-3db1-4515-b193-302b124f9b94\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f3543a61-3db1-4515-b193-302b124f9b94\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOMS-Id6kxST",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Filtering functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy_E3j-UWJYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unicode to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "#numbers add up to extraneous words in the vocabulary\n",
        "#hence we convert it to words so that numbers are now made of\n",
        "# individual words: 1979 --> One thousand and seventy nine\n",
        "def replace_numbers(text):\n",
        "    p = inflect.engine()\n",
        "    w = re.findall(r\"[0-9]+\", text)\n",
        "    for num in w:\n",
        "        text = text.replace(num, p.number_to_words(num))\n",
        "    return text\n",
        "#function does the following:\n",
        "# 1- Reduce redundancy\n",
        "#  1.1- by reducing words with two or more instances of uppercase and lowercase inflections\n",
        "#  1.2- by replacing numbers with word equivalents\n",
        "#  1.3- by reducing punctuation\n",
        "# 2- Add delimiters\n",
        "def preprocess_sentence(w, language='english'):\n",
        "    if language != 'hindi':\n",
        "        w = unicode_to_ascii(w.lower().strip())\n",
        "        w = replace_numbers(w)\n",
        "    \n",
        "    # creating a space between a word and the punctuation following it\n",
        "    w = re.sub(r\"([?.!,¿-])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    \n",
        "    if language != 'hindi':\n",
        "        # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "        w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    \n",
        "    w = w.rstrip().strip()\n",
        "    \n",
        "    # adding a start and an end token to the sentence\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "#function creates pair of sentences from language1 to language2\n",
        "def create_dataset(language_1_path, language_2_path):\n",
        "    english = open(language_1_path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    hindi = open(language_2_path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    word_pairs = [[preprocess_sentence(eng), preprocess_sentence(hin, language='hindi')] for eng, hin in zip(english, hindi)]\n",
        "    \n",
        "    return word_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUitrfulk7Ab",
        "colab_type": "text"
      },
      "source": [
        "## 1.3. Encapsulting Language Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltx_i_RcbupI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "    \n",
        "        self.create_index()\n",
        "    \n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "    \n",
        "        self.vocab = sorted(self.vocab)\n",
        "    \n",
        "        self.word2idx['<pad>'] = 0\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1\n",
        "    \n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvN5s6pxlJuq",
        "colab_type": "text"
      },
      "source": [
        "## 1.4. Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ynKqWbdawZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get length of the longest sentence\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "#create input and target tensors\n",
        "def load_dataset(language_1_path, language_2_path):\n",
        "    # creating language1 to language2 pairs\n",
        "    pairs = create_dataset(language_1_path, language_2_path)\n",
        "\n",
        "    #create languages and their vocabulary\n",
        "    # \"i am a programmer\" --> \"2 23 45 9\"\n",
        "    #where vocabulary(2)=i, vocabulary(23)=am, vocabulary(45)=a, vocabulary(9) = programmer\n",
        "    inp_lang = LanguageIndex(en for en, hi in pairs)\n",
        "    targ_lang = LanguageIndex(hi for en, hi in pairs)\n",
        "    \n",
        "    # Vectorize the input and target languages\n",
        "    \n",
        "    #English sentences\n",
        "    input_tensor = [[inp_lang.word2idx[s] for s in en.split(' ')] for en, hi in pairs]\n",
        "    \n",
        "    #Hindi sentences\n",
        "    target_tensor = [[targ_lang.word2idx[s] for s in hi.split(' ')] for en, hi in pairs]\n",
        "    \n",
        "\n",
        "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
        "    \n",
        "    #pad sentences so that every sentence is of same length\n",
        "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
        "                                                                 maxlen=max_length_inp,\n",
        "                                                                 padding='post')\n",
        "    \n",
        "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
        "                                                                  maxlen=max_length_tar, \n",
        "                                                                  padding='post')\n",
        "    \n",
        "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0TKMCNSf7pb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "60e85109-5108-476b-eae2-cd3fb24b8bad"
      },
      "source": [
        "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset('/content/english.txt', '/content/hindi.txt')\n",
        "print(\"Input shape: \", input_tensor.shape)\n",
        "print(\"Target shape: \", target_tensor.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape:  (3027, 92)\n",
            "Target shape:  (3027, 92)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lfd-iFmhrGt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e52ac35e-cc34-449b-eec5-8bf950fc526f"
      },
      "source": [
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.15, random_state=23)\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2572, 2572, 455, 455)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCzCnBVkl2Ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 256\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbjwBqPble9G",
        "colab_type": "text"
      },
      "source": [
        "# 2. Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_b--Y6xliMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gru(units):\n",
        "    return tf.keras.layers.CuDNNGRU(units, \n",
        "                                    return_sequences=True, \n",
        "                                    return_state=True, \n",
        "                                    recurrent_initializer='glorot_uniform')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnN5waiGmQkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.enc_units)\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)        \n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-TLOLH6mX0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "        # used for attention\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        \n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        \n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "        \n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        \n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "        \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fIzCskJmd1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CObo5ln2mhpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer()\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = 1 - np.equal(real, 0)\n",
        "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbM1u7Qqml63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBGxZfptmqal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        },
        "outputId": "fccd1bea-715b-4a7d-f203-ca3a06b139f0"
      },
      "source": [
        "EPOCHS = 15\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = encoder(inp, hidden)\n",
        "            \n",
        "            dec_hidden = enc_hidden\n",
        "            \n",
        "            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)       \n",
        "            \n",
        "            # Teacher forcing - feeding the target as the next input\n",
        "            for t in range(1, targ.shape[1]):\n",
        "                # passing enc_output to the decoder\n",
        "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "                \n",
        "                loss += loss_function(targ[:, t], predictions)\n",
        "                \n",
        "                # using teacher forcing\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "        \n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        variables = encoder.variables + decoder.variables\n",
        "        \n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        \n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.numpy()))\n",
        "    # saving (checkpoint) the model every 2 epochs\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.2157\n",
            "Epoch 1 Loss 0.2335\n",
            "Time taken for 1 epoch 65.73550987243652 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.2010\n",
            "Epoch 2 Loss 0.2278\n",
            "Time taken for 1 epoch 66.13814759254456 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.2014\n",
            "Epoch 3 Loss 0.2197\n",
            "Time taken for 1 epoch 65.91569662094116 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.1946\n",
            "Epoch 4 Loss 0.2114\n",
            "Time taken for 1 epoch 66.58022165298462 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1845\n",
            "Epoch 5 Loss 0.2034\n",
            "Time taken for 1 epoch 65.80890321731567 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.1830\n",
            "Epoch 6 Loss 0.1946\n",
            "Time taken for 1 epoch 65.99909329414368 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1738\n",
            "Epoch 7 Loss 0.1883\n",
            "Time taken for 1 epoch 65.41103529930115 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1638\n",
            "Epoch 8 Loss 0.1808\n",
            "Time taken for 1 epoch 65.64159178733826 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1558\n",
            "Epoch 9 Loss 0.1726\n",
            "Time taken for 1 epoch 65.81996488571167 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.1546\n",
            "Epoch 10 Loss 0.1678\n",
            "Time taken for 1 epoch 64.84161496162415 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.1455\n",
            "Epoch 11 Loss 0.1627\n",
            "Time taken for 1 epoch 64.68406391143799 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.1422\n",
            "Epoch 12 Loss 0.1559\n",
            "Time taken for 1 epoch 65.5006844997406 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.1400\n",
            "Epoch 13 Loss 0.1517\n",
            "Time taken for 1 epoch 64.99387717247009 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.1304\n",
            "Epoch 14 Loss 0.1470\n",
            "Time taken for 1 epoch 65.58026027679443 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.1256\n",
            "Epoch 15 Loss 0.1402\n",
            "Time taken for 1 epoch 65.2864260673523 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPw5G37Em8Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    \n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word2idx[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    \n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        \n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.idx2word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.idx2word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        \n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PH9emI9m-Tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='Greys')\n",
        "    \n",
        "    fontdict = {'fontsize': 14}\n",
        "    \n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK-QNXv_m_pD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
        "        \n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    \n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD5O8TT3nDtv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a61d272-6eab-4f16-e88c-ec3c88569eeb"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff07b090b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DMDdE7RnFDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "2fddb85c-ec23-4755-f6d5-f2d53bc6a9f9"
      },
      "source": [
        "translate(u'The police were able to remove Ganga and Chandra Kiran from the damaged car with some difficulty and took them to the Sundernagar civil hospital.', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> the police were able to remove ganga and chandra kiran from the damaged car with some difficulty and took them to the sundernagar civil hospital . <end>\n",
            "Predicted translation: पुलिस ने गंगा व चंद्र किरण को कड़ी मशक्कत के बाद क्षतिग्रस्त टैक्सी से बाहर निकाला और नागरिक अस्पताल सुंदरनगर ले गए। <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAIvCAYAAAD0y+aBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}